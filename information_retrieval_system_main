
# Code adapted from ChatGPT (OpenAI, 2025)

import xml.etree.ElementTree as ET
import re
import math
from collections import defaultdict, Counter

# Function to parse Cranfield documents
def parse_cranfield_documents(file_path):
    file_path = r"C:\Users\Dell\Downloads\searchfile\cran.all.1400.xml"
    tree = ET.parse(file_path)  # Should work if XML is fixed
    root = tree.getroot()
    print("XML Parsed Successfully!",root)
    
    documents = {}  # Store {doc_id: content}
    
    # for doc in root.findall('DOC'):
    #     doc_id = doc.find('DOCNO').text.strip()
    #     title = doc.find('TITLE').text.strip()
    #     text = doc.find('TEXT').text.strip()
    #     documents[doc_id] = title + " " + text  # Combine title and content
    for doc in root.findall('doc'):
        doc_id = doc.find('docno').text.strip() if doc.find('docno') is not None else "UNKNOWN"
        title_element = doc.find('title')
        title = title_element.text.strip() if title_element is not None and title_element.text else "No Title"
        text_element = doc.find('text')
        text = text_element.text.strip() if text_element is not None and text_element.text else "No Content"
        
        # Combine title and text for indexing
        documents[doc_id] = title + " " + text  
    
    return documents

# Function to parse Cranfield queries
def parse_cranfield_queries(file_path):
    tree = ET.parse(file_path)
    root = tree.getroot()
    
    queries = {}  # Store {query_id: query_text}
    
    for query in root.findall('top'):
        query_id = query.find('num').text.strip()
        query_text = query.find('title').text.strip()
        queries[query_id] = query_text
    
    return queries

# Function to tokenize text
def tokenize(text):
    return re.findall(r'\w+', text.lower())  # Extract words in lowercase

# Function to build an inverted index
def build_inverted_index(documents):
    inverted_index = defaultdict(set)  # {term: {doc_ids}}
    
    for doc_id, text in documents.items():
        words = tokenize(text)
        for word in words:
            inverted_index[word].add(doc_id)
    
    return inverted_index

# Function to compute TF-IDF ranking for a query
def rank_documents(query, documents, inverted_index):
    query_terms = tokenize(query)
    doc_scores = Counter()

    for term in query_terms:
        if term in inverted_index:
            doc_list = inverted_index[term]
            idf = math.log(len(documents) / (1 + len(doc_list)))  # Inverse Document Frequency
            for doc_id in doc_list:
                tf = documents[doc_id].lower().count(term)  # Term Frequency
                doc_scores[doc_id] += tf * idf  # TF-IDF score

    return sorted(doc_scores.items(), key=lambda x: x[1], reverse=True)  # Rank by score

def rank_documents_vsm(query, documents, inverted_index):
    query_terms = tokenize(query)
    query_vector = defaultdict(float)
    doc_vectors = defaultdict(lambda: defaultdict(float))
    doc_scores = Counter()

    # Compute TF-IDF for query terms
    for term in query_terms:
        idf = math.log(len(documents) / (1 + len(inverted_index.get(term, []))))  # IDF
        query_vector[term] += idf  # Use IDF as weight for query terms

    # Compute TF-IDF for document terms
    for term in query_terms:
        if term in inverted_index:
            doc_list = inverted_index[term]
            idf = math.log(len(documents) / (1 + len(doc_list)))  # IDF
            for doc_id in doc_list:
                tf = documents[doc_id].lower().count(term)  # Term Frequency
                doc_vectors[doc_id][term] += tf * idf  # TF-IDF weight

    # Compute cosine similarity
    for doc_id, vector in doc_vectors.items():
        dot_product = sum(query_vector[term] * vector.get(term, 0) for term in query_vector)
        query_norm = math.sqrt(sum(weight**2 for weight in query_vector.values()))
        doc_norm = math.sqrt(sum(weight**2 for weight in vector.values()))
        if query_norm * doc_norm > 0:
            doc_scores[doc_id] = dot_product / (query_norm * doc_norm)

    return sorted(doc_scores.items(), key=lambda x: x[1], reverse=True)

def rank_documents_bm25(query, documents, inverted_index, k1=2.0, b=0.9):
    query_terms = tokenize(query)
    doc_scores = Counter()
    
    avgdl = sum(len(tokenize(doc)) for doc in documents.values()) / len(documents)  # Average document length

    for term in query_terms:
        if term in inverted_index:
            doc_list = inverted_index[term]
            idf = math.log((len(documents) - len(doc_list) + 0.5) / (len(doc_list) + 0.5) + 1)  # IDF

            for doc_id in doc_list:
                tf = documents[doc_id].lower().count(term)
                dl = len(tokenize(documents[doc_id]))  # Document length
                score = idf * ((tf * (k1 + 1)) / (tf + k1 * (1 - b + b * dl / avgdl)))
                doc_scores[doc_id] += score

    return sorted(doc_scores.items(), key=lambda x: x[1], reverse=True)


def rank_documents_lm(query, documents, inverted_index, lambda_=0.7):
    query_terms = tokenize(query)
    collection_length = sum(len(tokenize(doc)) for doc in documents.values())
    collection_term_freqs = Counter()

    # Compute collection-wide term frequencies
    for text in documents.values():
        collection_term_freqs.update(tokenize(text))

    doc_scores = Counter()

    for doc_id, text in documents.items():
        doc_length = len(tokenize(text))
        score = 0

        for term in query_terms:
            tf_doc = text.lower().count(term)
            tf_collection = collection_term_freqs[term]
            p_t_d = tf_doc / doc_length if doc_length > 0 else 0
            p_t_c = tf_collection / collection_length if collection_length > 0 else 0

            score += math.log(lambda_ * p_t_d + (1 - lambda_) * p_t_c + 1e-10)

        doc_scores[doc_id] += score

    return sorted(doc_scores.items(), key=lambda x: x[1], reverse=True)



# Function to process queries and generate output for trec_eval
def process_queries(queries, documents, inverted_index, model="vsm", run_id="Run"):
    results = []

    for query_id, query_text in queries.items():
        if model == "vsm":
            ranked_docs = rank_documents_vsm(query_text, documents, inverted_index)
        elif model == "bm25":
            ranked_docs = rank_documents_bm25(query_text, documents, inverted_index)
        elif model == "lm":
            ranked_docs = rank_documents_lm(query_text, documents, inverted_index)
        else:
            raise ValueError(f"Unknown model: {model}")

        for rank, (doc_id, score) in enumerate(ranked_docs[:100], start=1):
            results.append(f"{query_id} 0 {doc_id} {rank} {score:.4f} {run_id}_{model}")

    return results


# Main Execution
documents = parse_cranfield_documents(r"C:\Users\Dell\Downloads\searchfile\cran.all.1400.xml")
queries = parse_cranfield_queries(r"C:\Users\Dell\Downloads\searchfile\cran.qry.xml")


inverted_index = build_inverted_index(documents)

# Generate results using VSM
vsm_results = process_queries(queries, documents, inverted_index, model="vsm", run_id="VSM_Run")

# Generate results using BM25
bm25_results = process_queries(queries, documents, inverted_index, model="bm25", run_id="BM25_Run")

# Generate results using Language Model
lm_results = process_queries(queries, documents, inverted_index, model="lm", run_id="LM_Run")

# Save results to files
with open("vsm_results.trec", "w") as f:
    
    f.write("\n".join(vsm_results))

with open("bm25_results.trec", "w") as f:
    f.write("\n".join(bm25_results))

with open("lm_results.trec", "w") as f:
    f.write("\n".join(lm_results))

print("Results saved for all models.")

